---
layout: post
title: Hosting Large Public Datasets on Amazon S3
date: '2008-09-04T22:00:00.004+01:00'
author: Tom White
tags:
- Amazon EC2
- Data
- Amazon S3
modified_time: '2008-09-12T20:46:21.241+01:00'
blogger_id: tag:blogger.com,1999:blog-8898949683610477251.post-7867943272436546694
blogger_orig_url: http://www.tom-e-white.com/2008/09/hosting-large-public-datasets-on-amazon.html
---

<span style="font-style:italic;"><span style="font-weight:bold;">Update</span>: I just thought of a quick and dirty way of doing this: just store your content on an extra large EC2 instance (holds up to 1690GB) and make the image public. Anyone can access it using their EC2 account, you just get charged for hosting the image.</span><br /><br />There's a great deal of interest in large, publicly available datasets (see, for example, <a href="http://groups.google.com/group/get-theinfo/browse_thread/thread/79e5b1159e533d52">this thread</a> from <a href="http://theinfo.org/">theinfo.org</a>), but for very large datasets it is still expensive to provide the bandwidth to distribute them. Imagine if you could get your hands on the data from a large web crawl, the kind of thing that the <a href="http://www.archive.org/">Internet Archive</a> produces. I'm sure people would discover some interesting things from it.<br /><br /><a href="http://aws.amazon.com/s3">Amazon S3</a> is an obvious choice for storing data for public consumption, but while the cost for storage may be reasonable, the cost for transfer can be crippling since the cost is not under the control of the data provider, being incurred <span style="font-style: italic;">for each transfer</span> (which is initiated by the user).<br /><br />For example, consider a 1TB dataset. With storage running at $0.15 per GB per month this works out at around $150 per month to host. With transfer costs costing $0.18 per GB, this dataset costs around $180 for each transfer out of Amazon! It's not surprising large datasets are not publicly hosted on S3.<br /><br />However, transferring data between S3 and EC2 is free, so could we limit transfers from S3 so they are only possible to EC2? You (or anyone else) could run an analysis on EC2 (using Hadoop, say) and only pay for the EC2 time. Or you could transfer it out of EC2 at your own expense. S3 doesn't support this option directly, but it is possible to emulate it with a bit of code.<br /><br />The idea (suggested by <a href="http://blog.lucene.com/">Doug Cutting</a>) is to make objects private on S3 to restrict access generally, then run a proxy on EC2 that is authorized to access the objects. The proxy only accepts connections from within EC2: any client that is outside Amazon's cloud is firewalled out. This combination ensures only EC2 instances can access the S3 objects, thus removing any bandwidth costs.<br /><br /><h3>Implementation</h3>I've written such a proxy. It's a Java servlet that uses the <a href="https://jets3t.dev.java.net/">JetS3t</a> library to add the correct <a href="http://docs.amazonwebservices.com/AmazonS3/2006-03-01/index.html?RESTAuthentication.html">Amazon S3 <code>Authorization</code> HTTP header</a> to gain access to the owner's objects on S3. If the proxy is running on the EC2 instance with hostname <span style="font-style: italic;">ec2-67-202-43-67.compute-1.amazonaws.com</span>, for example, then a request for<br /><pre>http://ec2-67-202-43-67.compute-1.amazonaws.com/bucket/object<br /></pre>is proxied to the protected object at<br /><pre>http://s3.amazonaws.com/bucket/object<br /></pre>To ensure that only clients on EC2 can get access to the proxy I set up an EC2 security group (which limits access to port 80):<br /><pre>ec2-add-group ec2-private-subnet -d "Group for all Amazon EC2 instances."<br />ec2-authorize ec2-private-subnet -p 80 -s 10.0.0.0/8</pre>Then by launching the proxy in this group, only machines on EC2 can connect. (Initially, I thought I had to add public IP addresses to the group -- which, incidentally, I found in <a href="http://developer.amazonwebservices.com/connect/thread.jspa?messageID=51028">this forum posting</a> -- but this is not necessary as the public DNS name of an EC2 instance resolves to the private IP address within EC2.) The AWS credentials to gain access to the S3 objects are passed in the user data, along with the hostname of S3:<br /><pre>ec2-run-instances -k gsg-keypair -g ec2-private-subnet \<br />-d "&lt;aws_access_key&gt; &lt;aws_secret_key&gt; s3.amazonaws.com" ami-fffd1996</pre>This AMI (ID <code>ami-fffd1996</code>) is publicly available, so anyone can use it by using the commands shown here. (The code is available <a href="http://s3.amazonaws.com/s3proxy/s3proxy-0.1.tar.gz">here</a>, under an Apache 2.0 license, but you don't need this if you only intend to run or use a proxy.)<br /><br /><h3>Demo</h3>Here's a resource on S3 that is protected: <span style="font-style:italic;">http://s3.amazonaws.com/tiling/private.txt</span>. When you try to retrieve it you get an authorization error:<br /><pre>% <span style="font-weight: bold;">curl http://s3.amazonaws.com/tiling/private.txt</span><br />&lt;?xml version="1.0" encoding="UTF-8"?&gt;<br />&lt;Error&gt;<br />&lt;Code&gt;AccessDenied&lt;/Code&gt;<br />&lt;Message&gt;Access Denied&lt;/Message&gt;<br />&lt;RequestId&gt;57E370CDDD9FE044&lt;/RequestId&gt;<br />&lt;HostId&gt;dA+9II1dYAjPE5aNsnRxhVoQ5qy3KCa6frkLg3SyTwzP3i2SQNCU534/v8NXXEnN&lt;/HostId&gt;<br />&lt;/Error&gt;</pre>With a proxy running, I still can't retrieve the resource via the proxy from outside EC2. It just times out due to the firewall rule:<br /><pre>% <span style="font-weight: bold;">curl http://ec2-67-202-56-11.compute-1.amazonaws.com/tiling/private.txt</span><br />curl: (7) couldn't connect to host</pre>But it does works from an EC2 machine (any EC2 machine):<br /><pre>% <span style="font-weight: bold;">curl http://ec2-67-202-56-11.compute-1.amazonaws.com/tiling/private.txt</span><br />secret</pre><h3>Conclusion</h3>By running a proxy on EC2, at 10 cents per hour (small instance) - or $72 a month, you can allow folks using EC2 to access your data on S3 for free. While running the proxy is not free, it is a fixed cost that might be acceptable to some organizations, particularly those that have an interest in making data publicly available (but can't stomach large bandwidth costs).<br /><br />A few questions:<br /><ul><li>Is this useful?</li><li>Is there a better way of doing it?</li><li>Can we have this built into S3 (please, Amazon)?</li></ul>